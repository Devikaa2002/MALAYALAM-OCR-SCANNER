{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b25305d1-f856-4723-be8d-23cb1ee8572f",
   "metadata": {},
   "source": [
    "## Step-by-Step Explanation of the Text Recognition Model with CTC Loss:\n",
    "\n",
    "This model tackles text recognition from images by combining CNNs for feature extraction and Bidirectional LSTMs for sequence modeling. Here's a breakdown focusing on the data flow and CTC loss:\n",
    "\n",
    "**1. Input:**\n",
    "\n",
    "* The model takes an image as input. The code defines the input shape based on pre-defined parameters like `img_w` (image width) and `img_h` (image height). This image has a single channel, likely representing grayscale values.\n",
    "\n",
    "**2. Feature Extraction with CNNs (VGG-like architecture):**\n",
    "\n",
    "* The image goes through several convolutional layers with ReLU activation and batch normalization. \n",
    "* These layers extract features from the image, like edges, shapes, and textures, that are relevant for recognizing text characters.\n",
    "* Max pooling layers are used for downsampling and reducing the dimensionality while retaining important information.\n",
    "\n",
    "**3. Reshape for RNN:**\n",
    "\n",
    "* The output from the CNNs is reshaped into a format suitable for feeding into the RNN layer. This typically involves flattening the spatial dimensions (width and height) into a single feature vector for each time step.\n",
    "\n",
    "**4. Embedding with Dense Layer:**\n",
    "\n",
    "* A dense layer projects the reshaped CNN output to a lower-dimensional space, creating a more compact representation of the features. This can be considered an embedding of the extracted features.\n",
    "\n",
    "**5. Bidirectional LSTMs for Sequence Modeling:**\n",
    "\n",
    "* Two stacked LSTMs are used in a bidirectional fashion.\n",
    "    * One LSTM processes the sequence (embedding) in the forward direction.\n",
    "    * Another LSTM processes the same sequence in the backward direction.\n",
    "* This allows the model to capture contextual information from both directions of the sequence, which is crucial for recognizing characters in the correct order.\n",
    "* Batch normalization is applied after each LSTM layer for stability.\n",
    "\n",
    "**6. Character Activations with Dense Layer:**\n",
    "\n",
    "* The final output from the Bidirectional LSTMs is fed into a dense layer with a number of neurons equal to the total number of characters the model needs to recognize.\n",
    "* This dense layer projects the internal representation to a space where each element represents the probability of a specific character being present at a particular position in the sequence.\n",
    "\n",
    "**7. Softmax Activation for Output Probabilities:**\n",
    "\n",
    "* A softmax activation function is applied to the output of the dense layer. \n",
    "* Softmax normalizes the output values between 0 and 1, representing the probability of each character class for each position in the sequence.\n",
    "\n",
    "**8. CTC Loss with Lambda Layer (Training Only):**\n",
    "\n",
    "* This step is only relevant during training.\n",
    "* A Lambda layer is used because Keras doesn't natively support loss functions with extra parameters.\n",
    "* The Lambda layer calls the `ctc_lambda_func` function, which takes the following arguments:\n",
    "    * Predicted outputs (`y_pred`): The probabilities of characters from the softmax layer.\n",
    "    * Labels (`labels`): The ground truth text sequence represented as one-hot encoded vectors.\n",
    "    * Input sequence length (`input_length`): The length of the input image sequence.\n",
    "    * Label length (`label_length`): The length of the ground truth text sequence.\n",
    "* The `ctc_lambda_func` ignores the first two outputs of `y_pred` as they are often unreliable. \n",
    "* It then calculates the CTC (Connectionist Temporal Classification) loss between the predicted probabilities and the ground truth labels, considering the sequence lengths.\n",
    "\n",
    "**9. Model Outputs:**\n",
    "\n",
    "* In training mode, the model returns a single output, which is the CTC loss calculated by the Lambda layer. This loss is used to backpropagate gradients and train the model parameters.\n",
    "* In evaluation mode, the model returns the character activation probabilities from the softmax layer. This allows you to predict the most likely character sequence for a given image.\n",
    "\n",
    "**Overall, this model leverages CNNs to extract features from the image, uses Bidirectional LSTMs to capture sequential information, and employs CTC loss for training, making it suitable for text recognition tasks.**\n",
    "\n",
    "**Connectionist Temporal Classification (CTC)** \n",
    "\n",
    "is a special type of loss function used for training neural networks, particularly Recurrent Neural Networks (RNNs) like LSTMs, in sequence labeling problems. Here's a breakdown of CTC and its role in the model you provided:\n",
    "\n",
    "**Challenges in Sequence Labeling:**\n",
    "\n",
    "* Traditional classification approaches assume a fixed-size output for each input. In sequence labeling tasks like text recognition, the output sequence (text) can have a variable length compared to the input image.\n",
    "* Additionally, there might be inconsistencies between the timing of features in the input sequence and the corresponding labels. For example, a single spoken phoneme might be stretched over multiple time steps in audio data.\n",
    "\n",
    "**What CTC Does:**\n",
    "\n",
    "* CTC addresses these challenges by allowing the model to learn the alignment between the input sequence and the output labels during training. \n",
    "* It doesn't require a strict one-to-one correspondence between input features and output labels.\n",
    "* CTC considers \"blank\" labels, which are inserted between characters in the predicted sequence. These blanks help the model handle variations in the timing of features and the length of the output sequence.\n",
    "\n",
    "**How CTC Works:**\n",
    "\n",
    "1. **Probabilities for Each Time Step:** The model outputs a probability distribution for each character (including a blank label) at every time step in the input sequence.\n",
    "2. **Alignment Paths:** CTC considers all possible alignments between the predicted sequence (with blanks) and the ground truth labels. These alignments define how the predicted characters and blanks correspond to the actual characters in the label sequence.\n",
    "3. **Marginal Probability:** CTC calculates a marginal probability by summing the probabilities of all valid alignments that lead to the ground truth label sequence.\n",
    "4. **Loss Calculation:** The CTC loss is computed as the negative log-likelihood of the marginal probability. Minimizing this loss during training encourages the model to generate output sequences that are more likely to align with the correct labels.\n",
    "\n",
    "**Benefits of CTC:**\n",
    "\n",
    "* Handles variable-length sequences without requiring pre-segmentation.\n",
    "* Accounts for potential inconsistencies between input features and output labels.\n",
    "* Provides robustness to noise and variations in the input data.\n",
    "\n",
    "**In the context of the text recognition model:**\n",
    "\n",
    "* CTC loss helps the model learn to predict the correct sequence of characters for an image, even if the characters have different durations or there are slight variations in their appearance.\n",
    "\n",
    "\n",
    "By incorporating CTC loss, the model can effectively learn to recognize text in images despite the challenges of variable sequence lengths and potential timing misalignments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d62adb-9266-42a3-8340-64450a10370f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#further model and parameter explanation\n",
    "import keras\n",
    "import random\n",
    "from keras import backend as K\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from keras.layers import Input, Conv2D, MaxPool2D, Dense,MaxPooling2D\n",
    "from keras.layers import AveragePooling2D, Flatten, Activation, Bidirectional\n",
    "from keras.layers import BatchNormalization, Dropout\n",
    "from keras.layers import Concatenate, Add, Multiply, Lambda\n",
    "from keras.layers import UpSampling2D, Reshape\n",
    "from keras.layers import add,concatenate\n",
    "from keras.layers import Reshape\n",
    "from keras.models import Model\n",
    "from keras.layers import LSTM,GRU\n",
    "import tensorflow as tf\n",
    "from parameter import *\n",
    "\n",
    "MAL_VECTOR = 'ംഃഅആഇഈഉഊഋഌഎഏഐഒഓഔകഖഗഘങചഛജഝഞടഠഡഢണതഥദധനഩപഫബഭമയരറലളഴവശഷസഹാിീുൂൃെേൈൊോൌ്ൎൗൺൻർൽൾ.,'\n",
    "\n",
    "ASCII_VECTOR = '-+=!@#$%^&*(){}[]|\\'\"\\\\/?<>;:0123456789'\n",
    "\n",
    "ENG_VECTOR = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz'\n",
    "\n",
    "CHAR_VECTOR = MAL_VECTOR\n",
    "\n",
    "letters = [letter for letter in CHAR_VECTOR] # letter array\n",
    "\n",
    "num_classes = len(letters) + 1               # total length of output chars + CTC separation char\n",
    "\n",
    "img_w, img_h = 350, 32\n",
    "\n",
    "# Network parameters\n",
    "batch_size = 64\n",
    "val_batch_size = 16\n",
    "\n",
    "downsample_factor = 4\n",
    "max_text_len = 60\n",
    "def ctc_loss_function(args):\n",
    "    \"\"\"\n",
    "    CTC loss function takes the values passed from the model returns the CTC loss using Keras Backend ctc_batch_cost function\n",
    "    \"\"\"\n",
    "    y_pred, y_true, input_length, label_length = args\n",
    "    # since the first couple outputs of the RNN tend to be garbage we need to discard them, found this from other CRNN approaches\n",
    "    # I Tried by including these outputs but the results turned out to be very bad and got very low accuracies on prediction\n",
    "    y_pred = y_pred[:, 2:, :]\n",
    "    return K.ctc_batch_cost(y_true, y_pred, input_length, label_length)\n",
    "\n",
    "\n",
    "# # Loss and train functions, network architecture\n",
    "def ctc_lambda_func(args):\n",
    "    y_pred, labels, input_length, label_length = args\n",
    "    # the 2 is critical here since the first couple outputs of the RNN\n",
    "    # tend to be garbage:\n",
    "    y_pred = y_pred[:, 2:, :]\n",
    "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n",
    "\n",
    "\n",
    "def get_Model(stage,drop_out_rate=0.35):\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        input_shape = (1, img_w, img_h)\n",
    "    else:\n",
    "        input_shape = (img_w, img_h, 1)\n",
    "\n",
    "    model_input=Input(shape=input_shape,name='the_input',dtype='float32')\n",
    "\n",
    "    # Convolution layer\n",
    "    model = Conv2D(64, (3, 3), padding='same', name='conv1', kernel_initializer='he_normal')(model_input)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "    model = MaxPooling2D(pool_size=(2, 2), name='max1')(model)\n",
    "\n",
    "    model = Conv2D(128, (3, 3), padding='same', name='conv2', kernel_initializer='he_normal')(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "    model = MaxPooling2D(pool_size=(2, 2), name='max2')(model)\n",
    "\n",
    "    model = Conv2D(256, (3, 3), padding='same', name='conv3', kernel_initializer='he_normal')(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "    model = Conv2D(256, (3, 3), padding='same', name='conv4', kernel_initializer='he_normal')(model)\n",
    "    model=Dropout(drop_out_rate)(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "    model = MaxPooling2D(pool_size=(1, 2), name='max3')(model)\n",
    "\n",
    "    model = Conv2D(512, (3, 3), padding='same', name='conv5', kernel_initializer='he_normal')(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "    model = Conv2D(512, (3, 3), padding='same', name='conv6')(model)\n",
    "    model=Dropout(drop_out_rate)(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "    model = MaxPooling2D(pool_size=(1, 2), name='max4')(model)\n",
    "\n",
    "    model = Conv2D(512, (2, 2), padding='same', kernel_initializer='he_normal', name='con7')(model)\n",
    "    model=Dropout(0.25)(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "\n",
    "    # CNN to RNN\n",
    "    model = Reshape(target_shape=((87, 1024)), name='reshape')(model)\n",
    "    model = Dense(64, activation='relu', kernel_initializer='he_normal', name='dense1')(model)\n",
    "\n",
    "    # RNN layer\n",
    "    model=Bidirectional(LSTM(256, return_sequences=True, kernel_initializer='he_normal'), merge_mode='sum')(model)\n",
    "    model=Bidirectional(LSTM(256, return_sequences=True, kernel_initializer='he_normal'), merge_mode='concat')(model)\n",
    "\n",
    "    # transforms RNN output to character activations:\n",
    "    model = Dense(num_classes, kernel_initializer='he_normal',name='dense2')(model)\n",
    "    y_pred = Activation('softmax', name='softmax')(model)\n",
    "\n",
    "\n",
    "    labels = Input(name='the_labels', shape=[max_text_len], dtype='float32')\n",
    "    input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
    "    label_length = Input(name='label_length', shape=[1], dtype='int64')\n",
    "\n",
    "    #CTC loss function\n",
    "    loss_out = Lambda(ctc_loss_function, output_shape=(1,),name='ctc')([y_pred, labels, input_length, label_length]) #(None, 1)\n",
    "\n",
    "    if stage=='train':\n",
    "        return model_input,y_pred,Model(inputs=[model_input, labels, input_length, label_length], outputs=loss_out)\n",
    "    else:\n",
    "        return Model(inputs=[model_input], outputs=y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1bbe88-1c26-4d26-8ca3-b6fb5ed1cd7c",
   "metadata": {},
   "source": [
    "## Line-by-Line Breakdown of the Text Recognition Code with CTC Loss:\n",
    "\n",
    "**Imports:**\n",
    "\n",
    "1. `import keras`: Imports the core Keras library for building neural networks.\n",
    "2. `import random`: Imports the `random` module, potentially for data augmentation or shuffling (not used in the provided code).\n",
    "3. `from keras import backend as K`: Imports the Keras backend, providing access to low-level functionalities.\n",
    "4. `import warnings`: Imports the `warnings` module to suppress warnings (not recommended practice).\n",
    "5. `warnings.filterwarnings(\"ignore\")`: Suppresses all warnings. It's generally better to address warnings rather than ignore them.\n",
    "6. **Keras Layer Imports:** Imports various Keras layers for building the model:\n",
    "    * `Input`, `Conv2D`, `MaxPool2D`, `Dense`, `AveragePooling2D`, `Flatten`, `Activation`, `Bidirectional`\n",
    "    * `BatchNormalization`, `Dropout`, `Concatenate`, `Add`, `Multiply`, `Lambda`\n",
    "    * `UpSampling2D`, `Reshape`\n",
    "7. `from keras.models import Model`: Imports the `Model` class for creating a Keras model.\n",
    "8. `from keras.layers import LSTM, GRU`: Imports LSTM and GRU layers for recurrent neural networks (not used in this model, uses Bidirectional LSTM).\n",
    "9. `import tensorflow as tf` (Optional): Imports TensorFlow, potentially used as the backend for Keras (might be redundant with keras import).\n",
    "10. `from parameter import *`: Imports parameters from a separate file (`parameter.py` not provided). \n",
    "\n",
    "**Character and Text Parameters:**\n",
    "\n",
    "11. `MAL_VECTOR`: Defines a string containing the characters used in the Malayalam language.\n",
    "12. `ASCII_VECTOR`: Defines a string containing ASCII characters. (Not used in the current model).\n",
    "13. `ENG_VECTOR`: Defines a string containing English characters. (Not used in the current model).\n",
    "14. `CHAR_VECTOR = MAL_VECTOR`: Selects the character set to be used for recognition (currently Malayalam).\n",
    "15. `letters = [letter for letter in CHAR_VECTOR]`: Creates a list of individual characters from the chosen character set.\n",
    "16. `num_classes = len(letters) + 1`: Calculates the total number of classes (characters + 1 for CTC separation).\n",
    "17. `img_w, img_h = 350, 32`: Defines the image width and height for the input data.\n",
    "\n",
    "**Network Training Parameters:**\n",
    "\n",
    "18. `batch_size = 64`: Sets the batch size for training, which is the number of images processed in one step.\n",
    "19. `val_batch_size = 16`: Sets the batch size for validation, which might be smaller than training batch size.\n",
    "20. `downsample_factor = 4`: Likely a parameter used for data pre-processing (not defined here).\n",
    "21. `max_text_len = 60`: Defines the maximum length of the ground truth text sequence (number of characters).\n",
    "\n",
    "**CTC Loss Function (ctc_loss_function):**\n",
    "\n",
    "22. `def ctc_loss_function(args):`: Defines a function named `ctc_loss_function` that takes arguments.\n",
    "23. `\"\"\"CTC loss function...\"\"\"`: Docstring explaining the function's purpose (CTC loss calculation).\n",
    "24. `y_pred, y_true, input_length, label_length = args`: Unpacks the arguments passed to the function:\n",
    "    * `y_pred`: Predicted probabilities for characters from the model.\n",
    "    * `y_true`: Ground truth labels (one-hot encoded text).\n",
    "    * `input_length`: Length of the input image sequence.\n",
    "    * `label_length`: Length of the ground truth text sequence.\n",
    "25. `y_pred = y_pred[:, 2:, :]`: Removes the first two outputs of the predicted probabilities (`y_pred`) as they are often unreliable in RNNs.\n",
    "26. `return K.ctc_batch_cost(y_true, y_pred, input_length, label_length)`: Returns the CTC loss calculated using the Keras backend function `ctc_batch_cost`.\n",
    "\n",
    "\n",
    "**CTC Lambda Function (ctc_lambda_func):**\n",
    "\n",
    "28. same as above *CTC Loss Function (ctc_loss_function):* "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cd8a57-6807-45cf-a836-c33793bf6470",
   "metadata": {},
   "source": [
    "The code you provided defines two functions related to CTC loss:\n",
    "\n",
    "1. `ctc_loss_function`: This function calculates the CTC loss during training.\n",
    "2. `ctc_lambda_func` (commented out): This function seems to be a redundant version of `ctc_loss_function`.\n",
    "\n",
    "**CTC Loss Explained:**\n",
    "\n",
    "CTC (Connectionist Temporal Classification) is a special type of loss function used for training neural networks, particularly Recurrent Neural Networks (RNNs) like LSTMs, in sequence labeling problems. Here's a breakdown of CTC loss:\n",
    "\n",
    "**Challenges in Sequence Labeling:**\n",
    "\n",
    "* Traditional classification approaches assume a fixed-size output for each input. In sequence labeling tasks like text recognition, the output sequence (text) can have a variable length compared to the input image.\n",
    "* Additionally, there might be inconsistencies between the timing of features in the input sequence and the corresponding labels. For example, a single spoken phoneme might be stretched over multiple time steps in audio data.\n",
    "\n",
    "**What CTC Does:**\n",
    "\n",
    "* CTC addresses these challenges by allowing the model to learn the alignment between the input sequence and the output labels during training. \n",
    "* It doesn't require a strict one-to-one correspondence between input features and output labels.\n",
    "* CTC considers \"blank\" labels, which are inserted between characters in the predicted sequence. These blanks help the model handle variations in the timing of features and the length of the output sequence.\n",
    "\n",
    "**How CTC Loss Works:**\n",
    "\n",
    "1. **Probabilities for Each Time Step:** The model outputs a probability distribution for each character (including a blank label) at every time step in the input sequence.\n",
    "2. **Alignment Paths:** CTC considers all possible alignments between the predicted sequence (with blanks) and the ground truth labels. These alignments define how the predicted characters and blanks correspond to the actual characters in the label sequence.\n",
    "3. **Marginal Probability:** CTC calculates a marginal probability by summing the probabilities of all valid alignments that lead to the ground truth label sequence.\n",
    "4. **Loss Calculation:** The CTC loss is computed as the negative log-likelihood of the marginal probability. Minimizing this loss during training encourages the model to generate output sequences that are more likely to align with the correct labels.\n",
    "\n",
    "**Benefits of CTC:**\n",
    "\n",
    "* Handles variable-length sequences without requiring pre-segmentation.\n",
    "* Accounts for potential inconsistencies between input features and output labels.\n",
    "* Provides robustness to noise and variations in the input data.\n",
    "\n",
    "**In the context of the text recognition model:**\n",
    "\n",
    "* CTC loss helps the model learn to predict the correct sequence of characters for an image, even if the characters have different durations or there are slight variations in their appearance.\n",
    "\n",
    "\n",
    "By incorporating CTC loss, the model can effectively learn to recognize text in images despite the challenges of variable sequence lengths and potential timing misalignments.\n",
    "\n",
    "**Note about ctc_lambda_func:**\n",
    "\n",
    "The `ctc_lambda_func` seems to be a commented-out version of `ctc_loss_function`. It's likely redundant and not used in the final model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cb68176-4c56-440b-9c08-f6a6557d75e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_Model explaination"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586b4027-2e96-4f36-9327-d2f9c75c290a",
   "metadata": {},
   "source": [
    "The `get_Model` function in the provided code defines the architecture of the text recognition model using Convolutional Neural Networks (CNNs) for feature extraction and Bidirectional LSTMs for sequence modeling with CTC loss for training. Here's a detailed breakdown:\n",
    "\n",
    "**Function Arguments:**\n",
    "\n",
    "1. `stage` (str): This argument specifies whether the model is for training (`'train'`) or prediction (`'test'`).\n",
    "2. `drop_out_rate` (float, optional): This argument controls the dropout rate for regularization (default 0.35).\n",
    "\n",
    "**Model Inputs:**\n",
    "\n",
    "* `model_input`: This is the input layer that takes an image with a pre-defined shape (`img_w`, `img_h`) and data type (`float32`). \n",
    "\n",
    "**CNN Feature Extraction:**\n",
    "\n",
    "The model goes through several convolutional layers with specific configurations:\n",
    "\n",
    "* `Conv2D` layers: Extract features from the image.\n",
    "* `BatchNormalization`: Normalizes the activations after each convolutional layer for stability.\n",
    "* `Activation('relu')`: Applies the ReLU activation function for non-linearity.\n",
    "* `MaxPooling2D` layers: Downsample the feature maps to reduce dimensionality.\n",
    "\n",
    "**Detailed Breakdown of CNN Layers:**\n",
    "\n",
    "1. `conv1`: Applies 64 filters of size 3x3 with padding and he_normal initialization.\n",
    "2. `max1`: Max pooling with pool size 2x2.\n",
    "3. `conv2`: Applies 128 filters of size 3x3 with padding and he_normal initialization.\n",
    "4. `max2`: Max pooling with pool size 2x2.\n",
    "5. `conv3`: Applies 256 filters of size 3x3 with padding and he_normal initialization.\n",
    "6. `conv4`: Applies 256 filters of size 3x3 with padding, he_normal initialization, and dropout (regularization).\n",
    "7. `max3`: Max pooling with pool size 1x2 (only downsamples vertically).\n",
    "8. `conv5`: Applies 512 filters of size 3x3 with padding and he_normal initialization.\n",
    "9. `conv6`: Applies 512 filters of size 3x3 with padding, he_normal initialization, and dropout.\n",
    "10. `max4`: Max pooling with pool size 1x2.\n",
    "11. `con7`: Applies 512 filters of size 2x2 with padding and he_normal initialization, followed by dropout.\n",
    "\n",
    "**Reshape for RNN:**\n",
    "\n",
    "* `reshape`: Reshapes the output from the CNN layers into a format suitable for feeding into the RNN layer (typically a 2D tensor with features for each time step).\n",
    "\n",
    "**Dense Layer for Feature Embedding:**\n",
    "\n",
    "* `dense1`: Applies a dense layer with 64 units and ReLU activation to project the CNN features to a lower-dimensional space, creating a more compact feature representation.\n",
    "\n",
    "\n",
    "**Bidirectional LSTMs for Sequence Modeling:**\n",
    "\n",
    "1. `Bidirectional(LSTM(256, return_sequences=True, kernel_initializer='he_normal'), merge_mode='sum')`: Applies two stacked LSTMs with 256 units each in a bidirectional fashion.\n",
    "    * `return_sequences=True`: Ensures the full output sequence is returned at each step.\n",
    "    * `kernel_initializer='he_normal'`: Initializes LSTM weights with he_normal initialization.\n",
    "    * `merge_mode='sum'`: Combines the outputs from the forward and backward LSTMs by summing them element-wise at each time step.\n",
    "2. `Bidirectional(LSTM(256, return_sequences=True, kernel_initializer='he_normal'), merge_mode='concat')`: Applies another set of bidirectional LSTMs with 256 units each.\n",
    "    * `merge_mode='concat'`: Combines the outputs from the forward and backward LSTMs by concatenating them along the feature dimension, resulting in a larger output dimension.\n",
    "\n",
    "**Character Activations with Dense Layer:**\n",
    "\n",
    "* `dense2`: Applies a dense layer with the number of classes (characters + 1 for CTC separation) and he_normal initialization to generate probabilities for each character class at each position in the sequence.\n",
    "* `Activation('softmax')`: Applies the softmax activation function to normalize the output probabilities, ensuring they sum to 1 and represent the probability of each character class.\n",
    "\n",
    "**Model Outputs:**\n",
    "\n",
    "* `y_pred`: The final output of the model, representing the predicted probabilities for each character class at each position in the sequence (after applying softmax).\n",
    "\n",
    "**Additional Layers for Training (if stage='train'):**\n",
    "\n",
    "* `labels`: Input layer for the ground truth text sequence (one-hot encoded).\n",
    "* `input_length`: Input layer for the length of the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d547d1ee-fc5a-4e83-a5cb-0ab9c254313e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
